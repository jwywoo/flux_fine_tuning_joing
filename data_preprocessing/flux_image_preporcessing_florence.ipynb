{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSacn7o_X-Ts",
        "outputId": "8b20535f-e916-4d99-e324-884301bba1d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "J1b0IYDVdAfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU pillow tiktoken"
      ],
      "metadata": {
        "id": "uyOgxM5eIgo3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "Uh5WSodlJiMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "FLUX_IMG_DIR = os.path.join(\"/content/drive/MyDrive\", 'FLUX DATASET')\n",
        "TEST_DATASET_THREE_PING = os.path.join(FLUX_IMG_DIR, 'TEST_DATASET_THREE_PING_FLORENCE')\n",
        "print(TEST_DATASET_THREE_PING)\n",
        "if not os.path.exists(TEST_DATASET_THREE_PING):\n",
        "  os.makedirs(TEST_DATASET_THREE_PING)"
      ],
      "metadata": {
        "id": "gVJn34njIrLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e1cd23-7d80-4cc2-87ad-9abd6e6f6a23"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING_FLORENCE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Supporting Methods"
      ],
      "metadata": {
        "id": "om82nUmXST2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def count_tokens(text):\n",
        "  encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "  num_tokens = len(encoding.encode(text))\n",
        "  return num_tokens"
      ],
      "metadata": {
        "id": "c2rlpsL5ScxI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, AutoModelForCausalLM\n",
        "\n",
        "def model_loading(torch_dtype, device):\n",
        "  return AutoModelForCausalLM.from_pretrained(\"microsoft/Florence-2-large\", torch_dtype=torch_dtype, trust_remote_code=True).to(device)\n",
        "\n",
        "def processor_loading():\n",
        "  return AutoProcessor.from_pretrained(\"microsoft/Florence-2-large\", trust_remote_code=True)\n"
      ],
      "metadata": {
        "id": "WNyweAjffY29"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "- Get list of images and txt\n",
        "- Iterate\n",
        "  - if a image has correlated txt file: Good!\n",
        "    - \"TEST_IMG_01.jpg\" : \"TETS_IMAGE_01.txt\"\n",
        "  - if a image doesn't have correlated txt file: Not Good!\n",
        "    - Show the image\n",
        "    - Get input\n",
        "      - input should be at least have length of 20 words\n",
        "      - if it's short get it again\n",
        "    - Save correlated txt file."
      ],
      "metadata": {
        "id": "8v6pGB-UJnyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of images\n",
        "image_list = [image for image in os.listdir(TEST_DATASET_THREE_PING) if image.endswith(\".jpg\")]\n",
        "# list of correlated text files\n",
        "text_list = [text.split(\".\")[0] for text in os.listdir(TEST_DATASET_THREE_PING) if text.endswith(\".txt\")]\n",
        "\n",
        "print(f\"Number of images: {len(image_list)}\")\n",
        "print(f\"Number of text files: {len(text_list)}\")\n",
        "\n",
        "image_needs_update = []\n",
        "for image in image_list:\n",
        "  if (image.split(\".\")[0] not in text_list):\n",
        "    image_needs_update.append(image)\n",
        "\n",
        "print(f\"Number of images needs update: {len(image_needs_update)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qz8C36mLdth",
        "outputId": "98021f05-0cbd-4de6-a5b5-3c41ef9fc32d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 10\n",
            "Number of text files: 10\n",
            "Number of images needs update: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model and Process Loading"
      ],
      "metadata": {
        "id": "BE53sItjgC0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "model = model_loading(\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "processor = processor_loading()"
      ],
      "metadata": {
        "id": "lnXlwkEodTNr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"<MORE_DETAILED_CAPTION>\"\n",
        "\n",
        "for image_file in image_needs_update:\n",
        "  # image setting\n",
        "  image = Image.open(os.path.join(TEST_DATASET_THREE_PING, image_file))\n",
        "  inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device, torch_dtype)\n",
        "\n",
        "  # getting a description about the image by Florence-2\n",
        "  generated_ids = model.generate(\n",
        "    input_ids=inputs[\"input_ids\"],\n",
        "    pixel_values=inputs[\"pixel_values\"],\n",
        "    max_new_tokens=1024,\n",
        "    num_beams=3,\n",
        "    do_sample=True\n",
        "  )\n",
        "  generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "  parsed_answer = processor.post_process_generation(generated_text, task=\"<MORE_DETAILED_CAPTION>\", image_size=(image.width, image.height))\n",
        "  generated_description = \"[trigger] \" + parsed_answer[prompt]\n",
        "\n",
        "  # result\n",
        "  display(image)\n",
        "  print(generated_description)\n",
        "  # saving the description about the image\n",
        "  text_file = image_file.split(\".\")[0] + \".txt\"\n",
        "  text_file_path = os.path.join(TEST_DATASET_THREE_PING, text_file)\n",
        "  with open(text_file_path, \"w\") as file:\n",
        "    file.write(generated_description)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "EP0GmChe7jE2"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}