{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwzssz84jgsJ"
   },
   "source": [
    "## Flux Fine Tuning Settings and Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idN6RQfOjgf-",
    "outputId": "754a0507-6e26-4121-e820-14d406f8517d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kxCle_4jzOI",
    "outputId": "08192981-c928-4e41-febf-1032747ac303"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ostris/ai-toolkit.git\n",
    "%cd ai-toolkit\n",
    "!git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZxqi9RFjMrx",
    "outputId": "e497205b-dc05-4fd0-dfde-2888a48088da"
   },
   "outputs": [],
   "source": [
    "!ls -al\n",
    "!pip install -qU torch\n",
    "!pip install -qU huggingface_hub\n",
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHxEPZXQnpSK"
   },
   "source": [
    "## YAML PATH CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yqq8WdfZnosq",
    "outputId": "8ec41ace-e570-46b4-e49a-e2c96094c7d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING_FLORENCE\n",
      "/content/drive/MyDrive/FLUX_YAML/test_three_ping_florence.yaml\n",
      "/content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING\n",
      "/content/drive/MyDrive/FLUX_YAML/test_three_ping.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "FLUX_IMG_DIR = os.path.join(\"/content/drive/MyDrive\", 'FLUX DATASET')\n",
    "TRAINING_YAML_PATH = os.path.join(\"/content/drive/MyDrive\", \"FLUX_YAML\")\n",
    "\n",
    "\n",
    "TEST_DATASET_THREE_PING_FLORENCE = os.path.join(FLUX_IMG_DIR, 'TEST_DATASET_THREE_PING_FLORENCE')\n",
    "TEST_YAML_FLORENCE = os.path.join(TRAINING_YAML_PATH, \"test_three_ping_florence.yaml\")\n",
    "print(TEST_DATASET_THREE_PING_FLORENCE)\n",
    "print(TEST_YAML_FLORENCE)\n",
    "\n",
    "TEST_DATASET_THREE_PING = os.path.join(FLUX_IMG_DIR, 'TEST_DATASET_THREE_PING')\n",
    "TEST_YAML = os.path.join(TRAINING_YAML_PATH, \"test_three_ping.yaml\")\n",
    "print(TEST_DATASET_THREE_PING)\n",
    "print(TEST_YAML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blLT8FJup0g0"
   },
   "source": [
    "## HuggingFace Hub Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AB9ZqS-NYK2p"
   },
   "outputs": [],
   "source": [
    "!pip install -qU huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiSxQuTFp3xq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN_WRITE = userdata.get('HF_TOKEN_WRITE')\n",
    "login(token=HF_TOKEN_WRITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deMuFY9QpYzi"
   },
   "source": [
    "## Fine-Tuning Start! - with yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pk_9edTEpYl6",
    "outputId": "cf34df7a-4fa9-4e9c-a66f-8e34709ccdcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/ai-toolkit/config\n",
      "total 20\n",
      "drwxr-xr-x  3 root root 4096 Nov 28 07:36 .\n",
      "drwxr-xr-x 17 root root 4096 Nov 28 07:35 ..\n",
      "drwxr-xr-x  3 root root 4096 Nov 28 07:35 examples\n",
      "-rw-------  1 root root 4732 Nov 28 07:36 test_three_ping.yaml\n",
      "/content/ai-toolkit\n"
     ]
    }
   ],
   "source": [
    "# Copy yaml file from Googel Drive to ai-toolkit/confing/\n",
    "!cp /content/drive/MyDrive/FLUX_YAML/test_three_ping.yaml config/test_three_ping.yaml\n",
    "# !cp /content/drive/MyDrive/FLUX_YAML/test_three_ping_florence.yaml config/test_three_ping_florence.yaml\n",
    "%cd config\n",
    "!ls -al\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "U-ZwZs9ks1fM",
    "outputId": "aa6f305f-62f4-45a7-a9fa-367e5ed7e199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "job: extension\n",
      "config:\n",
      "  # 파일명 선정\n",
      "  name: \"IAM_THREE_PING_TEST_V1\"\n",
      "  process:\n",
      "    - type: 'sd_trainer'\n",
      "      # session, sample, 가중치를 저장할 루트 폴더 경로 지정\n",
      "      training_folder: \"output\"\n",
      "      # N번의 한번씩 성능을 확인하려면 주석을 해제\n",
      "      performance_log_every: 250\n",
      "      device: cuda:0\n",
      "      # Trigger Word가 정해졌으면 학습정보의 Caption(사진 설명)에 [trigger]를 추가하면 정해진 Trigger Word로 바뀜\n",
      "      # 만약에 없다면은 학습정보의 Caption(사진 설명)에 자동으로 추가됨\n",
      "      trigger_word: \"IATPT\"\n",
      "      network:\n",
      "        type: \"lora\"\n",
      "        linear: 16\n",
      "        linear_alpha: 16\n",
      "      save:\n",
      "        dtype: float16 # 저장할 때의 데이터 형태\n",
      "        save_every: 250 # 저장 주기\n",
      "        max_step_saves_to_keep: 4 # 얼마나 보유할 지\n",
      "        push_to_hub: false # true로 바꾼다면 HuggingFace에 업로드 됩니다.\n",
      "        # 여기에 Hugging Face의 write권한이 있는 토큰과 저장소 정보를 작성하세요 안그러면 입력하라고 뜹니다.\n",
      "        # hf_repo_id: jwywoo/test_three_ping\n",
      "        # hf_private: true #whether the repo is private or public\n",
      "      datasets:\n",
      "        # 데이터셋은 학습할 사진이 들어간 폴더입니다. 사진에 대한 설명의 경우 txt  파일로 사진파일의 이름과 일치해서 저장해야합니다.\n",
      "        # 예를들어, image2.jpg의 경우 image2.txt가 있어야 합니다. 그리고 현재 사용가능한 파일 형식의 경우 jpg, jpeg, png가 있으니 조심하세용\n",
      "        # 사진의 경우 자동으로 크기가 조정고 해상도 또한 지정한대로 저장이됩니다\n",
      "        # 윈도우 운영체제를 사용할 경우 아래의 경로 형식을 사용하세요.\n",
      "        # \"C:\\\\path\\\\to\\\\images\\\\folder\"\n",
      "        - folder_path: \"/content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING\"\n",
      "          caption_ext: \"txt\"\n",
      "          caption_dropout_rate: 0.05  # will drop out the caption 5% of time\n",
      "          shuffle_tokens: false  # shuffle caption order, split by commas\n",
      "          cache_latents_to_disk: true  # leave this true unless you know what you're doing\n",
      "          resolution: [ 512, 768, 1024 ]  # flux enjoys multiple resolutions\n",
      "      train:\n",
      "        batch_size: 1\n",
      "        steps: 500  # 저체 트레이닝 횟수입니다. 500에서 4000 정도가 좋습니다.\n",
      "        gradient_accumulation_steps: 1\n",
      "        train_unet: true\n",
      "        train_text_encoder: false  # Flux에 해당하지 않는 부분입니다.\n",
      "        gradient_checkpointing: true  # vram이 많지 않다면 그냥 true로 해두세요\n",
      "        noise_scheduler: \"flowmatch\" # 학습에서만 사용하세요\n",
      "        optimizer: \"adamw8bit\"\n",
      "        lr: 1e-4\n",
      "        # pre-training sampled을 지나칠라면 주석해제\n",
      "#        skip_first_sample: true\n",
      "        # 샘플링을 완전 안쓰려면 주석해제\n",
      "#        disable_sampling: true\n",
      "        # Vell Curved 가중치를 사용하려면 주석을 해제하세요. 실험단계지만 어쩔때는 더 좋은 결과를 만들어 냅니다.\n",
      "#        linear_timesteps: true\n",
      "\n",
      "        # EMA 학습을 부드럽게 진행하도록 도움을 줍니다. 하지만 느려지는 원인중 하나입니다. 그냥 내비두세요.\n",
      "        ema_config:\n",
      "          use_ema: true\n",
      "          ema_decay: 0.99\n",
      "\n",
      "        # will probably need this if gpu supports it for flux, other dtypes may not work correctly\n",
      "        # GPU가 flux를 지원한다면 그냥 내비두세요. 다른 데이터 형태는 작동되지 않을 수 있습니다.\n",
      "        dtype: bf16\n",
      "      model:\n",
      "        # Hugging Face 모델명이 혹은 로컬이라면 경로 지정\n",
      "        name_or_path: \"black-forest-labs/FLUX.1-dev\"\n",
      "        is_flux: true\n",
      "        quantize: true  # run 8bit mixed precision\n",
      "#        low_vram: true  # uncomment this if the GPU is connected to your monitors. It will use less vram to quantize, but is slower.\n",
      "      sample:\n",
      "        sampler: \"flowmatch\" # 위에 있는 train.noise_scheduler와 일치해야합니다.\n",
      "        sample_every: 250 # 샘플 생성 주기\n",
      "        width: 1024\n",
      "        height: 1024\n",
      "        prompts:\n",
      "          # 셈플생성을 위한 Prompt,  프롬프트에 [trigger]를 추가하면 trigger word로 변경될겁니다. \n",
      "          - \"[trigger] holding a sign that says 'I LOVE PROMPTS!'\"\n",
      "          - \"[trigger] laughing at the same time\"\n",
      "          - \"[trigger] surrounded by puppies and cats\"\n",
      "        neg: \"\"  # Flux는 부정 String(Prompts)를 사용하지 않습니다.\n",
      "        seed: 42\n",
      "        walk_seed: true\n",
      "        guidance_scale: 4\n",
      "        sample_steps: 20\n",
      "# 생성될 모델에 대한 추가적인 정보를 입력하세요.\n",
      "meta:\n",
      "  name: \"[name]\"\n",
      "  version: '1.0'"
     ]
    }
   ],
   "source": [
    "!cat config/test_three_ping.yaml\n",
    "# !cat config/test_three_ping_florence.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IEsZgSKpiPv",
    "outputId": "91e2ad8c-3881-4942-d658-9683820d139e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 job\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "2024-11-28 07:37:26.364092: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-28 07:37:26.380589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-28 07:37:26.401440: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-28 07:37:26.408312: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-28 07:37:26.423479: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-28 07:37:27.627580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "{\n",
      "    \"type\": \"sd_trainer\",\n",
      "    \"training_folder\": \"output\",\n",
      "    \"performance_log_every\": 250,\n",
      "    \"device\": \"cuda:0\",\n",
      "    \"trigger_word\": \"IATPT\",\n",
      "    \"network\": {\n",
      "        \"type\": \"lora\",\n",
      "        \"linear\": 16,\n",
      "        \"linear_alpha\": 16\n",
      "    },\n",
      "    \"save\": {\n",
      "        \"dtype\": \"float16\",\n",
      "        \"save_every\": 250,\n",
      "        \"max_step_saves_to_keep\": 4,\n",
      "        \"push_to_hub\": false\n",
      "    },\n",
      "    \"datasets\": [\n",
      "        {\n",
      "            \"folder_path\": \"/content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING\",\n",
      "            \"caption_ext\": \"txt\",\n",
      "            \"caption_dropout_rate\": 0.05,\n",
      "            \"shuffle_tokens\": false,\n",
      "            \"cache_latents_to_disk\": true,\n",
      "            \"resolution\": [\n",
      "                512,\n",
      "                768,\n",
      "                1024\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"train\": {\n",
      "        \"batch_size\": 1,\n",
      "        \"steps\": 500,\n",
      "        \"gradient_accumulation_steps\": 1,\n",
      "        \"train_unet\": true,\n",
      "        \"train_text_encoder\": false,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"noise_scheduler\": \"flowmatch\",\n",
      "        \"optimizer\": \"adamw8bit\",\n",
      "        \"lr\": 0.0001,\n",
      "        \"ema_config\": {\n",
      "            \"use_ema\": true,\n",
      "            \"ema_decay\": 0.99\n",
      "        },\n",
      "        \"dtype\": \"bf16\"\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"name_or_path\": \"black-forest-labs/FLUX.1-dev\",\n",
      "        \"is_flux\": true,\n",
      "        \"quantize\": true\n",
      "    },\n",
      "    \"sample\": {\n",
      "        \"sampler\": \"flowmatch\",\n",
      "        \"sample_every\": 250,\n",
      "        \"width\": 1024,\n",
      "        \"height\": 1024,\n",
      "        \"prompts\": [\n",
      "            \"[trigger] holding a sign that says 'I LOVE PROMPTS!'\",\n",
      "            \"[trigger] laughing at the same time\",\n",
      "            \"[trigger] surrounded by puppies and cats\"\n",
      "        ],\n",
      "        \"neg\": \"\",\n",
      "        \"seed\": 42,\n",
      "        \"walk_seed\": true,\n",
      "        \"guidance_scale\": 4,\n",
      "        \"sample_steps\": 20\n",
      "    }\n",
      "}\n",
      "Using EMA\n",
      "/content/ai-toolkit/extensions_built_in/sd_trainer/SDTrainer.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "\n",
      "#############################################\n",
      "# Running job: IAM_THREE_PING_TEST_V1\n",
      "#############################################\n",
      "\n",
      "\n",
      "Running  1 process\n",
      "Loading Flux model\n",
      "Loading transformer\n",
      "transformer/config.json: 100% 378/378 [00:00<00:00, 2.63MB/s]\n",
      "(…)ion_pytorch_model.safetensors.index.json: 100% 121k/121k [00:00<00:00, 3.56MB/s]\n",
      "(…)pytorch_model-00001-of-00003.safetensors: 100% 9.98G/9.98G [00:25<00:00, 394MB/s]\n",
      "(…)pytorch_model-00002-of-00003.safetensors: 100% 9.95G/9.95G [00:29<00:00, 335MB/s]\n",
      "(…)pytorch_model-00003-of-00003.safetensors: 100% 3.87G/3.87G [00:10<00:00, 373MB/s]\n",
      "Quantizing transformer\n",
      "scheduler/scheduler_config.json: 100% 273/273 [00:00<00:00, 2.06MB/s]\n",
      "Loading vae\n",
      "vae/config.json: 100% 820/820 [00:00<00:00, 7.24MB/s]\n",
      "diffusion_pytorch_model.safetensors: 100% 168M/168M [00:00<00:00, 276MB/s] \n",
      "Loading t5\n",
      "tokenizer_2/tokenizer_config.json: 100% 20.8k/20.8k [00:00<00:00, 86.9MB/s]\n",
      "spiece.model: 100% 792k/792k [00:00<00:00, 13.1MB/s]\n",
      "tokenizer_2/tokenizer.json: 100% 2.42M/2.42M [00:00<00:00, 23.1MB/s]\n",
      "tokenizer_2/special_tokens_map.json: 100% 2.54k/2.54k [00:00<00:00, 19.5MB/s]\n",
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "text_encoder_2/config.json: 100% 782/782 [00:00<00:00, 5.94MB/s]\n",
      "(…)t_encoder_2/model.safetensors.index.json: 100% 19.9k/19.9k [00:00<00:00, 82.7MB/s]\n",
      "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
      "model-00001-of-00002.safetensors:   0% 0.00/4.99G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0% 10.5M/4.99G [00:00<06:03, 13.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1% 62.9M/4.99G [00:00<00:53, 92.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3% 168M/4.99G [00:00<00:18, 264MB/s]  \u001b[A\n",
      "model-00001-of-00002.safetensors:   5% 262M/4.99G [00:01<00:11, 400MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7% 357M/4.99G [00:01<00:09, 501MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9% 440M/4.99G [00:01<00:08, 569MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10% 524M/4.99G [00:01<00:09, 486MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12% 598M/4.99G [00:01<00:08, 536MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14% 724M/4.99G [00:01<00:06, 676MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16% 818M/4.99G [00:01<00:05, 739MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19% 933M/4.99G [00:01<00:05, 797MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21% 1.05G/4.99G [00:02<00:04, 887MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23% 1.15G/4.99G [00:02<00:04, 903MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25% 1.27G/4.99G [00:02<00:03, 966MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28% 1.37G/4.99G [00:02<00:03, 974MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30% 1.48G/4.99G [00:02<00:03, 963MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32% 1.59G/4.99G [00:02<00:03, 998MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34% 1.70G/4.99G [00:02<00:03, 1.00GB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36% 1.80G/4.99G [00:02<00:03, 837MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  38% 1.90G/4.99G [00:03<00:05, 581MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39% 1.97G/4.99G [00:03<00:08, 337MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41% 2.03G/4.99G [00:03<00:08, 331MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42% 2.11G/4.99G [00:04<00:07, 387MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44% 2.19G/4.99G [00:04<00:06, 451MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45% 2.25G/4.99G [00:04<00:05, 460MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46% 2.32G/4.99G [00:04<00:05, 489MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48% 2.38G/4.99G [00:04<00:05, 510MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49% 2.44G/4.99G [00:04<00:05, 452MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50% 2.50G/4.99G [00:04<00:05, 462MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51% 2.55G/4.99G [00:04<00:05, 454MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52% 2.60G/4.99G [00:05<00:05, 435MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53% 2.65G/4.99G [00:05<00:05, 448MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55% 2.73G/4.99G [00:05<00:04, 502MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56% 2.78G/4.99G [00:07<00:27, 80.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58% 2.89G/4.99G [00:07<00:15, 139MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  61% 3.03G/4.99G [00:07<00:08, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63% 3.13G/4.99G [00:07<00:06, 285MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66% 3.29G/4.99G [00:07<00:03, 432MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69% 3.42G/4.99G [00:07<00:02, 557MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71% 3.54G/4.99G [00:08<00:02, 611MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73% 3.64G/4.99G [00:08<00:02, 637MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75% 3.77G/4.99G [00:08<00:01, 750MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78% 3.88G/4.99G [00:08<00:01, 828MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80% 4.00G/4.99G [00:08<00:01, 664MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82% 4.09G/4.99G [00:08<00:01, 586MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83% 4.17G/4.99G [00:09<00:01, 576MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85% 4.24G/4.99G [00:09<00:01, 541MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86% 4.30G/4.99G [00:09<00:01, 486MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87% 4.37G/4.99G [00:11<00:06, 101MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91% 4.54G/4.99G [00:11<00:02, 191MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95% 4.73G/4.99G [00:11<00:00, 311MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100% 4.99G/4.99G [00:11<00:00, 417MB/s]\n",
      "Downloading shards:  50% 1/2 [00:12<00:12, 12.13s/it]\n",
      "model-00002-of-00002.safetensors:   0% 0.00/4.53G [00:00<?, ?B/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   0% 10.5M/4.53G [00:00<04:08, 18.2MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   0% 21.0M/4.53G [00:00<02:43, 27.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   3% 136M/4.53G [00:00<00:19, 224MB/s]  \u001b[A\n",
      "model-00002-of-00002.safetensors:   5% 220M/4.53G [00:01<00:12, 339MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   7% 315M/4.53G [00:01<00:09, 465MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   9% 388M/4.53G [00:01<00:09, 429MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  10% 461M/4.53G [00:01<00:08, 492MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  13% 577M/4.53G [00:01<00:06, 644MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  15% 661M/4.53G [00:01<00:05, 676MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  16% 744M/4.53G [00:01<00:05, 691MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  19% 870M/4.53G [00:01<00:04, 834MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  22% 996M/4.53G [00:02<00:03, 898MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  24% 1.10G/4.53G [00:02<00:03, 860MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  26% 1.20G/4.53G [00:02<00:06, 531MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  28% 1.27G/4.53G [00:02<00:06, 495MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  29% 1.33G/4.53G [00:02<00:07, 417MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  31% 1.38G/4.53G [00:03<00:09, 320MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  31% 1.43G/4.53G [00:03<00:09, 325MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  32% 1.47G/4.53G [00:03<00:10, 292MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  33% 1.51G/4.53G [00:03<00:10, 290MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  34% 1.55G/4.53G [00:03<00:11, 255MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  35% 1.58G/4.53G [00:04<00:11, 265MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  36% 1.61G/4.53G [00:04<00:10, 272MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  36% 1.65G/4.53G [00:04<00:12, 228MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  37% 1.70G/4.53G [00:04<00:10, 281MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  38% 1.73G/4.53G [00:04<00:09, 282MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  39% 1.76G/4.53G [00:04<00:11, 244MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  40% 1.79G/4.53G [00:04<00:11, 230MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  40% 1.82G/4.53G [00:05<00:13, 204MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  41% 1.86G/4.53G [00:05<00:11, 223MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  42% 1.89G/4.53G [00:05<00:12, 216MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  44% 1.97G/4.53G [00:05<00:07, 352MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  46% 2.08G/4.53G [00:05<00:04, 518MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  49% 2.20G/4.53G [00:05<00:03, 697MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  52% 2.36G/4.53G [00:05<00:02, 909MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  55% 2.50G/4.53G [00:05<00:02, 1.01GB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  58% 2.61G/4.53G [00:06<00:02, 858MB/s] \u001b[A\n",
      "model-00002-of-00002.safetensors:  60% 2.71G/4.53G [00:06<00:03, 584MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  62% 2.79G/4.53G [00:06<00:03, 567MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  63% 2.86G/4.53G [00:06<00:03, 443MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  65% 2.93G/4.53G [00:07<00:04, 367MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  66% 2.98G/4.53G [00:07<00:04, 333MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  67% 3.02G/4.53G [00:07<00:04, 325MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  68% 3.08G/4.53G [00:07<00:03, 372MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  71% 3.21G/4.53G [00:07<00:02, 500MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  72% 3.27G/4.53G [00:07<00:02, 511MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  74% 3.33G/4.53G [00:08<00:04, 252MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  76% 3.45G/4.53G [00:08<00:02, 363MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  79% 3.59G/4.53G [00:08<00:01, 497MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  81% 3.67G/4.53G [00:08<00:01, 469MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  83% 3.74G/4.53G [00:09<00:01, 469MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  84% 3.81G/4.53G [00:09<00:01, 456MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  85% 3.87G/4.53G [00:09<00:01, 433MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  87% 3.93G/4.53G [00:09<00:02, 282MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  89% 4.05G/4.53G [00:09<00:01, 402MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  92% 4.17G/4.53G [00:10<00:00, 459MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  94% 4.24G/4.53G [00:10<00:01, 262MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  95% 4.29G/4.53G [00:10<00:00, 285MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  96% 4.34G/4.53G [00:10<00:00, 299MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  97% 4.39G/4.53G [00:11<00:00, 333MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  98% 4.45G/4.53G [00:12<00:00, 89.3MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  99% 4.49G/4.53G [00:13<00:00, 98.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors: 100% 4.53G/4.53G [00:17<00:00, 256MB/s] \n",
      "Downloading shards: 100% 2/2 [00:30<00:00, 15.02s/it]\n",
      "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  2.83it/s]\n",
      "Quantizing T5\n",
      "Loading clip\n",
      "text_encoder/config.json: 100% 613/613 [00:00<00:00, 4.41MB/s]\n",
      "model.safetensors: 100% 246M/246M [00:05<00:00, 44.6MB/s] \n",
      "tokenizer/tokenizer_config.json: 100% 705/705 [00:00<00:00, 3.89MB/s]\n",
      "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 2.15MB/s]\n",
      "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 1.96MB/s]\n",
      "tokenizer/special_tokens_map.json: 100% 588/588 [00:00<00:00, 3.42MB/s]\n",
      "making pipe\n",
      "preparing\n",
      "create LoRA network. base dim (rank): 16, alpha: 16\n",
      "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
      "create LoRA for Text Encoder: 0 modules.\n",
      "create LoRA for U-Net: 494 modules.\n",
      "enable LoRA for U-Net\n",
      "Dataset: /content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING\n",
      "  -  Preprocessing image dimensions\n",
      "100% 10/10 [00:00<00:00, 29187.92it/s]\n",
      "  -  Found 10 images\n",
      "Bucket sizes for /content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING:\n",
      "576x448: 1 files\n",
      "640x384: 3 files\n",
      "576x384: 6 files\n",
      "3 buckets made\n",
      "Caching latents for /content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING\n",
      " - Saving latents to disk\n",
      "Caching latents to disk: 100% 10/10 [00:00<00:00, 857.19it/s]\n",
      "Dataset: /content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING\n",
      "  -  Preprocessing image dimensions\n",
      "100% 10/10 [00:00<00:00, 24470.85it/s]\n",
      "  -  Found 10 images\n",
      "Bucket sizes for /content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING:\n",
      "832x576: 2 files\n",
      "960x576: 3 files\n",
      "896x576: 5 files\n",
      "3 buckets made\n",
      "Caching latents for /content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING\n",
      " - Saving latents to disk\n",
      "Caching latents to disk: 100% 10/10 [00:00<00:00, 4426.71it/s]\n",
      "Dataset: /content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING\n",
      "  -  Preprocessing image dimensions\n",
      "100% 10/10 [00:00<00:00, 27999.36it/s]\n",
      "  -  Found 10 images\n",
      "Bucket sizes for /content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING:\n",
      "1152x832: 1 files\n",
      "1280x768: 3 files\n",
      "1216x832: 5 files\n",
      "1344x768: 1 files\n",
      "4 buckets made\n",
      "Caching latents for /content/drive/MyDrive/FLUX DATASET/TEST_DATASET_THREE_PING\n",
      " - Saving latents to disk\n",
      "Caching latents to disk: 100% 10/10 [00:00<00:00, 3971.50it/s]\n",
      "Generating baseline samples before training\n",
      "IAM_THREE_PING_TEST_V1:  50% 249/500 [09:33<10:11,  2.44s/it, lr: 1.0e-04 loss: 3.392e-01]\n",
      "Generating Images:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Generating Images:  33% 1/3 [00:18<00:37, 18.62s/it]\u001b[A\n",
      "Generating Images:  67% 2/3 [00:37<00:18, 18.58s/it]\u001b[A\n",
      "Generating Images: 100% 3/3 [00:55<00:00, 18.57s/it]\u001b[A\n",
      "Saving at step 250\n",
      "Saved to output/IAM_THREE_PING_TEST_V1/optimizer.pt\n",
      "IAM_THREE_PING_TEST_V1:  50% 249/500 [09:36<10:11,  2.44s/it, lr: 1.0e-04 loss: 3.392e-01]\n",
      "Timer 'IAM_THREE_PING_TEST_V1 Timer':\n",
      " - 2.3271s avg - train_loop, num = 10\n",
      " - 1.3652s avg - backward, num = 10\n",
      " - 0.6944s avg - predict_unet, num = 10\n",
      " - 0.2388s avg - reset_batch, num = 8\n",
      " - 0.1145s avg - optimizer_step, num = 10\n",
      " - 0.0676s avg - encode_prompt, num = 10\n",
      " - 0.0644s avg - calculate_loss, num = 10\n",
      " - 0.0016s avg - get_batch, num = 10\n",
      " - 0.0016s avg - preprocess_batch, num = 10\n",
      " - 0.0011s avg - prepare_noise, num = 10\n",
      " - 0.0003s avg - prepare_latents, num = 10\n",
      " - 0.0001s avg - batch_cleanup, num = 10\n",
      " - 0.0000s avg - prepare_prompt, num = 10\n",
      " - 0.0000s avg - scheduler_step, num = 10\n",
      " - 0.0000s avg - grad_setup, num = 10\n",
      " - 0.0000s avg - log_to_tensorboard, num = 2\n",
      "\n",
      "IAM_THREE_PING_TEST_V1: 100% 499/500 [19:00<00:02,  2.28s/it, lr: 1.0e-04 loss: 3.655e-01]\n",
      "\n",
      "Saved to output/IAM_THREE_PING_TEST_V1/optimizer.pt\n"
     ]
    }
   ],
   "source": [
    "# Initiate fine-tuning\n",
    "# python run.py config/whatever_yaml_file.yaml\n",
    "!python run.py config/test_three_ping.yaml\n",
    "# !python run.py config/test_three_ping_florence.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KIez8202pf0"
   },
   "source": [
    "## Fine-tuning with Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "8NhGJit52uFP",
    "outputId": "ccfa9b02-9a58-4374-976a-c6dde66c9b85"
   },
   "outputs": [],
   "source": [
    "!ls -al\n",
    "%cd /content/ai-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "woXM5FIXRr8P",
    "outputId": "244dd9b3-45b2-4f5b-e002-72936f2a1c80"
   },
   "outputs": [],
   "source": [
    "!python flux_train_ui.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0esKa24By2HP"
   },
   "source": [
    "# HuggingFace Uploads\n",
    "- Google Drive First\n",
    "- HuggingFace Uploads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FH8fkfWxatE3"
   },
   "source": [
    "## Creating Repo on HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "EtEY4fQiaxIU",
    "outputId": "9f17f7c9-2470-47fd-e65f-bff71f84d9be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "RepoUrl('https://huggingface.co/jwywoo/iam-three-ping-test-v1', endpoint='https://huggingface.co', repo_type='model', repo_id='jwywoo/iam-three-ping-test-v1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import create_repo\n",
    "\n",
    "repo_name = \"iam-three-ping-test-v1\"\n",
    "create_repo(repo_name, repo_type=\"model\", private=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnvrl6pmZ3id"
   },
   "source": [
    "## HuggingFace Uploads - Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VJfJcwmZ8VA",
    "outputId": "aa3500a5-e29f-4f5e-e6ea-7c156133f93b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/FLUX_YAML/fine_tuned_models/IAM_THREE_PING_TEST_V1\n",
      "['config.yaml', 'IAM_THREE_PING_TEST_V1_000000250.safetensors', 'IAM_THREE_PING_TEST_V1.safetensors', 'optimizer.pt', 'samples']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DRIVE_PATH = os.path.join(\"/content/drive\", \"MyDrive\")\n",
    "FLUX_YAML = os.path.join(DRIVE_PATH, \"FLUX_YAML\")\n",
    "FINE_TUNED_MODELS = os.path.join(FLUX_YAML, \"fine_tuned_models\")\n",
    "THREE_PING_TEST_DIR = os.path.join(FINE_TUNED_MODELS, \"IAM_THREE_PING_TEST_V1\")\n",
    "print(THREE_PING_TEST_DIR)\n",
    "\n",
    "if not os.path.exists(THREE_PING_TEST_DIR):\n",
    "  print(\"Path doesn't exist!\")\n",
    "print(os.listdir(THREE_PING_TEST_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226,
     "referenced_widgets": [
      "484d474943de4933aaa1987a20ee7865",
      "57b273f88b5d40b4bc171c99dcac3a89",
      "086f355c0dbe4eb39589008275c6ba1d",
      "7ae57328c4774bb4929a8a4e9ddced1d",
      "8ed5d8b38c9a4e4c863b9da2c3fda452",
      "57a8a79650b74c98bc2ecf2560b19540",
      "dc5e5bc79e3b4122bf3cd0920eba2fba",
      "107ee4d651864bb0ab3eae95ee47b3d4",
      "1bdea77e3a3346dd8053574437d8df0a",
      "f248fe6633354fe1b5ecf34609996b3f",
      "3186ffe0510b4c79b5d78a4c176a996d",
      "9622fd46e1a34afda3f8472dd87f7bbf",
      "188c4b53ecf04f06ab075bb0dd8a089a",
      "4c88c54930624212a601957490b5add9",
      "12a728acbaf44bceb386b82250306d3f",
      "78fd59ba4ccf4880abe830412c51198f",
      "8abc947c000e4fa881f3d4f1495204b4",
      "416aa841bdc54f27900461a025fc31cb",
      "09f7ca2e7e874ff2b52811fc1b76d7e3",
      "1fde84726fa641c9b5b3ab71da0c7b74",
      "265a293c230e49ef94ad28973834db98",
      "cecb445e73ba41d9a44c9a0727ea717c"
     ]
    },
    "id": "p6s3Z24fz1IC",
    "outputId": "c22d55be-5bc8-438a-99f3-cac61a7946b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jwywoo/iam-three-ping-test-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484d474943de4933aaa1987a20ee7865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IAM_THREE_PING_TEST_V1_000000250.safetensors:   0%|          | 0.00/172M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9622fd46e1a34afda3f8472dd87f7bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IAM_THREE_PING_TEST_V1.safetensors:   0%|          | 0.00/172M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import upload_file\n",
    "\n",
    "repo_name = \"jwywoo/iam-three-ping-test-v1\"\n",
    "\n",
    "print(repo_name)\n",
    "\n",
    "files_uploading = ['IAM_THREE_PING_TEST_V1_000000250.safetensors', 'IAM_THREE_PING_TEST_V1.safetensors']\n",
    "for file_name in files_uploading:\n",
    "  path_to_file = os.path.join(THREE_PING_TEST_DIR, file_name)\n",
    "  upload_file(\n",
    "      path_or_fileobj=path_to_file,\n",
    "      path_in_repo=file_name,\n",
    "      repo_id=repo_name,\n",
    "      repo_type=\"model\",\n",
    "      commit_message=f\"Upload {file_name}\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbv3cnDwhJ4Q"
   },
   "source": [
    "## HuggingFace Uploads - Folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "MZ7CT9hfhyZv",
    "outputId": "2c203394-da9f-467d-b53c-5ef20698819c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jwywoo/iam-three-ping-test-v1/commit/f30bdd1b195f5fee0804dc495f17fd886b8198a0', commit_message='Upload samples', commit_description='', oid='f30bdd1b195f5fee0804dc495f17fd886b8198a0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/jwywoo/iam-three-ping-test-v1', endpoint='https://huggingface.co', repo_type='model', repo_id='jwywoo/iam-three-ping-test-v1'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import upload_folder\n",
    "\n",
    "folder_path = os.path.join(THREE_PING_TEST_DIR, \"samples\")\n",
    "repo_name = \"jwywoo/iam-three-ping-test-v1\"\n",
    "\n",
    "upload_folder(\n",
    "    folder_path=folder_path,\n",
    "    repo_id=repo_name,\n",
    "    repo_type=\"model\",\n",
    "    path_in_repo = \"samples/\",\n",
    "    commit_message=f\"Upload samples\"\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "bwzssz84jgsJ",
    "iHxEPZXQnpSK",
    "blLT8FJup0g0",
    "deMuFY9QpYzi",
    "0KIez8202pf0",
    "0esKa24By2HP"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "086f355c0dbe4eb39589008275c6ba1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_107ee4d651864bb0ab3eae95ee47b3d4",
      "max": 171969416,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1bdea77e3a3346dd8053574437d8df0a",
      "value": 171969416
     }
    },
    "09f7ca2e7e874ff2b52811fc1b76d7e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "107ee4d651864bb0ab3eae95ee47b3d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12a728acbaf44bceb386b82250306d3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_265a293c230e49ef94ad28973834db98",
      "placeholder": "​",
      "style": "IPY_MODEL_cecb445e73ba41d9a44c9a0727ea717c",
      "value": " 172M/172M [00:03&lt;00:00, 51.7MB/s]"
     }
    },
    "188c4b53ecf04f06ab075bb0dd8a089a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8abc947c000e4fa881f3d4f1495204b4",
      "placeholder": "​",
      "style": "IPY_MODEL_416aa841bdc54f27900461a025fc31cb",
      "value": "IAM_THREE_PING_TEST_V1.safetensors: 100%"
     }
    },
    "1bdea77e3a3346dd8053574437d8df0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1fde84726fa641c9b5b3ab71da0c7b74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "265a293c230e49ef94ad28973834db98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3186ffe0510b4c79b5d78a4c176a996d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "416aa841bdc54f27900461a025fc31cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "484d474943de4933aaa1987a20ee7865": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_57b273f88b5d40b4bc171c99dcac3a89",
       "IPY_MODEL_086f355c0dbe4eb39589008275c6ba1d",
       "IPY_MODEL_7ae57328c4774bb4929a8a4e9ddced1d"
      ],
      "layout": "IPY_MODEL_8ed5d8b38c9a4e4c863b9da2c3fda452"
     }
    },
    "4c88c54930624212a601957490b5add9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09f7ca2e7e874ff2b52811fc1b76d7e3",
      "max": 171969416,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fde84726fa641c9b5b3ab71da0c7b74",
      "value": 171969416
     }
    },
    "57a8a79650b74c98bc2ecf2560b19540": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57b273f88b5d40b4bc171c99dcac3a89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57a8a79650b74c98bc2ecf2560b19540",
      "placeholder": "​",
      "style": "IPY_MODEL_dc5e5bc79e3b4122bf3cd0920eba2fba",
      "value": "IAM_THREE_PING_TEST_V1_000000250.safetensors: 100%"
     }
    },
    "78fd59ba4ccf4880abe830412c51198f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ae57328c4774bb4929a8a4e9ddced1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f248fe6633354fe1b5ecf34609996b3f",
      "placeholder": "​",
      "style": "IPY_MODEL_3186ffe0510b4c79b5d78a4c176a996d",
      "value": " 172M/172M [00:02&lt;00:00, 72.1MB/s]"
     }
    },
    "8abc947c000e4fa881f3d4f1495204b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ed5d8b38c9a4e4c863b9da2c3fda452": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9622fd46e1a34afda3f8472dd87f7bbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_188c4b53ecf04f06ab075bb0dd8a089a",
       "IPY_MODEL_4c88c54930624212a601957490b5add9",
       "IPY_MODEL_12a728acbaf44bceb386b82250306d3f"
      ],
      "layout": "IPY_MODEL_78fd59ba4ccf4880abe830412c51198f"
     }
    },
    "cecb445e73ba41d9a44c9a0727ea717c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc5e5bc79e3b4122bf3cd0920eba2fba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f248fe6633354fe1b5ecf34609996b3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
